{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624070a9",
   "metadata": {},
   "source": [
    "# Predict Gamma to use the model with the other base models in stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5eb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost\n",
    "import optuna\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import confusion_matrix, log_loss, average_precision_score\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9771df",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/olli/Projects/Kaggle/ICR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'train.csv'\n",
    "greek_csv = 'greeks.csv'\n",
    "test_csv = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7113702",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.join(folder, train_csv)\n",
    "greek_csv_path = os.path.join(folder, greek_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea521a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_csv_path)\n",
    "df_g = pd.read_csv(greek_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7fbbc",
   "metadata": {},
   "source": [
    "# Preprocess Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6999ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['EJ']\n",
    "num_features = list(df.columns)\n",
    "for remove_value in ['Id', 'EJ', 'Class']:\n",
    "    num_features.remove(remove_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e318748",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_num = SimpleImputer(strategy='median')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a standardscaler due to the outliers\n",
    "scaler_num = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cat = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('Num_Imputer', imputer_num),\n",
    "    ('Num_Scaler', scaler_num)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('Cat_Imputer', imputer_cat),\n",
    "    ('Cat_Encoder', encoder_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipe = ColumnTransformer([\n",
    "    ('Num_Pipe', num_pipeline, num_features),\n",
    "    ('Cat_Pipe', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f93534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs; use same split like in final training\n",
    "X_DF = df.copy()\n",
    "X_DF['Alpha'] = df_g.Alpha\n",
    "X_DF['Gamma'] = df_g.Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefe6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92cf5b",
   "metadata": {},
   "source": [
    "Recall from Notebook_1: Gamma_M had the highest correlation with the Target and most datapoints were gamma_M. gamma_H also has a high correlation but were less datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01902f",
   "metadata": {},
   "source": [
    "# Function to add the multi-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86871b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: The target is a pd series and need to be converted to a multi class numpy array\n",
    "\n",
    "def create_gamma_label(series, onehot=True):\n",
    "    df = series.copy()\n",
    "    \n",
    "    class_labels = []\n",
    "    \n",
    "    # for each values add the class number (M==0, H==1, other==2)\n",
    "    for value in df.values:\n",
    "        if value == 'M':\n",
    "            class_labels.append(0)\n",
    "        elif value == 'H':\n",
    "            class_labels.append(1)\n",
    "        else:\n",
    "            class_labels.append(2)\n",
    "            \n",
    "    # since this is a multiclass classification the labels need to be like this:\n",
    "    # [1, 0, 0] for [gamma_M, gamma_H, gamma_other]\n",
    "    labels_onehot = []\n",
    "    \n",
    "    for label in class_labels:\n",
    "        labels_onehot.append(np.eye(3)[label])  # makes easy onehot\n",
    "    \n",
    "    labels_onehot = np.array(labels_onehot)\n",
    "    \n",
    "    if onehot:\n",
    "        return labels_onehot\n",
    "    else:\n",
    "        return np.array(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the function\n",
    "exp_gamma = X_DF['Gamma'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1522a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gamma.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gamma_encoded = create_gamma_label(exp_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gamma_encoded[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753589cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also calculate the initial weights to try\n",
    "exp_gamma.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32997a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exp_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gamma_enc_2 = create_gamma_label(exp_gamma, onehot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gamma_enc_2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(exp_gamma_enc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563db470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set weight M to 1\n",
    "# weight H\n",
    "print(f'H: {445 / 53}; other: {445 / (617 - 445 - 53)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfcf8f",
   "metadata": {},
   "source": [
    "# Optimize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff243eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    # weights\n",
    "    weight_M = trial.suggest_float('weight_M', 0.7, 1.5)\n",
    "    weight_H = trial.suggest_float('weight_H', 6, 11)\n",
    "    weight_other = trial.suggest_float('weight_other', 3, 4.5)\n",
    "    \n",
    "    # use the auc score here with weighted param for the imbalanced task and to utilize propapilities\n",
    "    scores = []\n",
    "\n",
    "    seeds = list(range(0, 10))\n",
    "\n",
    "    for seed in seeds:\n",
    "\n",
    "        cv = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "        # use alpha+gamma to draw stratified samples\n",
    "        for train_index, valid_index in cv.split(X_DF, X_DF[['Alpha', 'Gamma']].copy()):\n",
    "\n",
    "            # take all columns for the features since the ColumnTransformer will only select the defined ones\n",
    "            X_train, y_train = X_DF.iloc[train_index], X_DF.loc[train_index, 'Gamma']\n",
    "            X_valid, y_valid = X_DF.iloc[valid_index], X_DF.loc[valid_index, 'Gamma']\n",
    "\n",
    "            # use defined pipeline\n",
    "            X_train = preprocess_pipe.fit_transform(X_train)\n",
    "            X_valid = preprocess_pipe.transform(X_valid)  # no fit\n",
    "\n",
    "            # apply function to add labels\n",
    "            y_train = create_gamma_label(y_train, onehot=False)\n",
    "            y_valid = create_gamma_label(y_valid, onehot=False)\n",
    "            \n",
    "            # create the sample weight to assign an individual weight for each point\n",
    "            dict_weight = {0:weight_M, 1:weight_H, 2: weight_other}\n",
    "            sample_weights = np.array([dict_weight[i] for i in y_train])\n",
    "            \n",
    "            xgb = xgboost.XGBClassifier(n_estimators=trial.suggest_int('n_estimators', 5, 1000),\n",
    "                                        max_depth=trial.suggest_int('max_depth', 2, 10),\n",
    "                                        learning_rate=trial.suggest_float('lr', 0.01, 1),\n",
    "                                        gamma=trial.suggest_float('gamma', 0, 1),\n",
    "                                        min_child_weight=trial.suggest_float('min_child_weight', 0, 10),\n",
    "                                        max_delta_step=trial.suggest_int('max_delta_step', 0, 10),\n",
    "                                        subsample=trial.suggest_float('subsample', 0.5, 1),\n",
    "                                        colsample_bynode=trial.suggest_float('colsample_bynode', 0.5, 1),\n",
    "                                        colsample_bytree=trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "                                        colsample_bylevel=trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "                                        reg_lambda=trial.suggest_float('reg_lambda', 0.0001, 0.1, log=True),\n",
    "                                        objective='multi:softprob',\n",
    "                                        num_class=3,\n",
    "                                        #sample_weight=sample_weights,\n",
    "                                        )\n",
    "            xgb.fit(X_train,\n",
    "                    y_train,\n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                    sample_weight=sample_weights,\n",
    "                    early_stopping_rounds=trial.suggest_int('early_stop', 1, 1000),\n",
    "                    verbose=0\n",
    "                    )\n",
    "\n",
    "            xgb.fit(X_train, y_train)\n",
    "\n",
    "            y_val_pred = xgb.predict_proba(X_valid)  # currently (n_samples, 3) for 3 classes\n",
    "            \n",
    "            # y_valid is (n_samples, ) for xgb, metric needs onehot\n",
    "            y_valid_onehot = np.eye(len(np.unique(y_valid)))[y_valid]\n",
    "                        \n",
    "            score = average_precision_score(y_valid_onehot, y_val_pred, average='weighted')\n",
    "            scores.append(score)\n",
    "\n",
    "    final_score = np.array(scores).mean()\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca04536",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b445e08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f138da",
   "metadata": {},
   "source": [
    "0.9138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de541bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf29609",
   "metadata": {},
   "source": [
    "# Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f312bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_2(trial):\n",
    "    \n",
    "    # weights\n",
    "    weight_M = trial.suggest_float('weight_M', 1.2, 1.7)\n",
    "    weight_H = trial.suggest_float('weight_H', 5, 7)\n",
    "    weight_other = trial.suggest_float('weight_other', 3.25, 4.25)\n",
    "    \n",
    "    # use the auc score here with weighted param for the imbalanced task and to utilize propapilities\n",
    "    scores = []\n",
    "\n",
    "    seeds = list(range(0, 10))\n",
    "\n",
    "    for seed in seeds:\n",
    "\n",
    "        cv = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "        # use alpha+gamma to draw stratified samples\n",
    "        for train_index, valid_index in cv.split(X_DF, X_DF[['Alpha', 'Gamma']].copy()):\n",
    "\n",
    "            # take all columns for the features since the ColumnTransformer will only select the defined ones\n",
    "            X_train, y_train = X_DF.iloc[train_index], X_DF.loc[train_index, 'Gamma']\n",
    "            X_valid, y_valid = X_DF.iloc[valid_index], X_DF.loc[valid_index, 'Gamma']\n",
    "\n",
    "            # use defined pipeline\n",
    "            X_train = preprocess_pipe.fit_transform(X_train)\n",
    "            X_valid = preprocess_pipe.transform(X_valid)  # no fit\n",
    "\n",
    "            # apply function to add labels\n",
    "            y_train = create_gamma_label(y_train, onehot=False)\n",
    "            y_valid = create_gamma_label(y_valid, onehot=False)\n",
    "            \n",
    "            # create the sample weight to assign an individual weight for each point\n",
    "            dict_weight = {0:weight_M, 1:weight_H, 2: weight_other}\n",
    "            sample_weights = np.array([dict_weight[i] for i in y_train])\n",
    "            \n",
    "            xgb = xgboost.XGBClassifier(n_estimators=trial.suggest_int('n_estimators', 850, 910),\n",
    "                                        max_depth=3,\n",
    "                                        learning_rate=trial.suggest_float('lr', 0.02, 0.1),\n",
    "                                        gamma=trial.suggest_float('gamma', 0.05, 0.25),\n",
    "                                        min_child_weight=trial.suggest_float('min_child_weight', 0.6, 1),\n",
    "                                        max_delta_step=trial.suggest_int('max_delta_step', 6, 10),\n",
    "                                        subsample=trial.suggest_float('subsample', 0.5, 0.7),\n",
    "                                        colsample_bynode=trial.suggest_float('colsample_bynode', 0.85, 1),\n",
    "                                        colsample_bytree=trial.suggest_float('colsample_bytree', 0.75, 0.95),\n",
    "                                        colsample_bylevel=trial.suggest_float('colsample_bylevel', 0.4, 0.6),\n",
    "                                        reg_lambda=trial.suggest_float('reg_lambda', 0.1, 10, log=True),\n",
    "                                        objective='multi:softprob',\n",
    "                                        num_class=3,\n",
    "                                        #sample_weight=sample_weights,\n",
    "                                        )\n",
    "            xgb.fit(X_train,\n",
    "                    y_train,\n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                    sample_weight=sample_weights,\n",
    "                    early_stopping_rounds=trial.suggest_int('early_stop', 200, 260),\n",
    "                    verbose=0\n",
    "                    )\n",
    "\n",
    "            xgb.fit(X_train, y_train)\n",
    "\n",
    "            y_val_pred = xgb.predict_proba(X_valid)  # currently (n_samples, 3) for 3 classes\n",
    "            \n",
    "            # y_valid is (n_samples, ) for xgb, metric needs onehot\n",
    "            y_valid_onehot = np.eye(len(np.unique(y_valid)))[y_valid]\n",
    "                        \n",
    "            score = average_precision_score(y_valid_onehot, y_val_pred, average='weighted')\n",
    "            scores.append(score)\n",
    "\n",
    "    final_score = np.array(scores).mean()\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124cdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_2 = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a76f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "study_2.optimize(objective_2, n_trials=40, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_2.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db2f75",
   "metadata": {},
   "source": [
    "0.91545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaae13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_2.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_xgb_params = {'weight_M': 1.6574709291749559,\n",
    "         'weight_H': 6.494618704275055,\n",
    "         'weight_other': 4.141839934777784,\n",
    "         'n_estimators': 904,\n",
    "         'max_depth': 3,\n",
    "         'lr': 0.025917942386337954,\n",
    "         'gamma': 0.23400159239280982,\n",
    "         'min_child_weight': 0.8473270431776004,\n",
    "         'max_delta_step': 9,\n",
    "         'subsample': 0.5309248067433621,\n",
    "         'colsample_bynode': 0.9777134591145428,\n",
    "         'colsample_bytree': 0.8372737842373374,\n",
    "         'colsample_bylevel': 0.5711105969683837,\n",
    "         'reg_lambda': 0.10145045118989354,\n",
    "         'early_stop': 218,\n",
    "         'objective': 'multi:softprob',\n",
    "         'num_class': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c329ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular",
   "language": "python",
   "name": "tabular"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
